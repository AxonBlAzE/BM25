{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Qjjt1qFBi5nX"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from multiprocessing import Pool, cpu_count"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BM25Okapi:\n",
        "  def __init__(self, corpus, tokenizer=None, k1=1.5, b=0.75, epsilon=0.25):\n",
        "    self.k1 = k1\n",
        "    self.b = b\n",
        "    self.epsilon = epsilon\n",
        "    self.corpus_size = 0\n",
        "    self.avgdl = 0\n",
        "    self.doc_freqs = []\n",
        "    self.idf = {}\n",
        "    self.doc_len = []\n",
        "    \n",
        "    nd = self._initialize(corpus)\n",
        "    self._calc_idf(nd)\n",
        "\n",
        "  def _initialize(self, corpus):\n",
        "    nd = {}  # word -> number of documents with word\n",
        "    num_doc = 0\n",
        "\n",
        "    for document in corpus:\n",
        "       self.doc_len.append(len(document))\n",
        "       num_doc += len(document)\n",
        "       \n",
        "       frequencies = {}\n",
        "       for word in document:\n",
        "         if word not in frequencies:\n",
        "           frequencies[word] = 0\n",
        "         frequencies[word] += 1\n",
        "       self.doc_freqs.append(frequencies)\n",
        "\n",
        "       for word, freq in frequencies.items():\n",
        "          try:\n",
        "            nd[word]+=1\n",
        "          except KeyError:\n",
        "            nd[word] = 1\n",
        "       self.corpus_size += 1\n",
        "    \n",
        "    self.avgdl = num_doc / self.corpus_size\n",
        "    return nd\n",
        "\n",
        "  def _calc_idf(self, nd):\n",
        "    idf_sum = 0\n",
        "    negative_idfs = []\n",
        "\n",
        "    for word, freq in nd.items():\n",
        "      idf = math.log(self.corpus_size - freq + 0.5) - math.log(freq + 0.5)\n",
        "      self.idf[word] = idf\n",
        "      idf_sum += idf\n",
        "      if idf < 0:\n",
        "        negative_idfs.append(word)\n",
        "    self.average_idf = idf_sum / len(self.idf)\n",
        "    eps = self.epsilon * self.average_idf\n",
        "    for word in negative_idfs:\n",
        "      self.idf[word] = eps\n",
        "\n",
        "  def get_top_n(self, query, documents, n=5):\n",
        "    assert self.corpus_size == len(documents), \"The documents given don't match the index corpus!\"\n",
        "    scores = self.get_scores(query)\n",
        "    top_n = np.argsort(scores)[::-1][:n]\n",
        "    return [documents[i] for i in top_n]\n",
        "\n",
        "  def get_scores(self, query):\n",
        "    score = np.zeros(self.corpus_size)\n",
        "    doc_len = np.array(self.doc_len)\n",
        "\n",
        "    for q in query:\n",
        "       q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
        "       score += (self.idf.get(q) or 0) * (q_freq * (self.k1 + 1) /(q_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl)))\n",
        "    \n",
        "    return score"
      ],
      "metadata": {
        "id": "a_cut8xBjDlP"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}