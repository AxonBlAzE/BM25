{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install rank_bm25\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0r_WeBF53Iz",
        "outputId": "9006e969-88a2-4c69-f238-ee4c50c02f13"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.9/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from rank_bm25) (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from multiprocessing import Pool, cpu_count"
      ],
      "metadata": {
        "id": "dzQgiwJHkcxu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BM25Okapi:\n",
        "  def __init__(self, corpus, tokenizer=None, k1=1.5, b=0.75, epsilon=0.25):\n",
        "    self.k1 = k1\n",
        "    self.b = b\n",
        "    self.epsilon = epsilon\n",
        "    self.corpus_size = 0\n",
        "    self.avgdl = 0\n",
        "    self.doc_freqs = []\n",
        "    self.idf = {}\n",
        "    self.doc_len = []\n",
        "    \n",
        "    nd = self._initialize(corpus)\n",
        "    self._calc_k(nd)\n",
        "\n",
        "  def _initialize(self, corpus):\n",
        "    nd = {}  # word -> number of documents with word\n",
        "    num_doc = 0\n",
        "\n",
        "    for document in corpus:\n",
        "       self.doc_len.append(len(document))\n",
        "       num_doc += len(document)\n",
        "       \n",
        "       frequencies = {}\n",
        "       for word in document:\n",
        "         if word not in frequencies:\n",
        "           frequencies[word] = 0\n",
        "         frequencies[word] += 1\n",
        "       self.doc_freqs.append(frequencies)\n",
        "\n",
        "       for word, freq in frequencies.items():\n",
        "          try:\n",
        "            nd[word]+=1\n",
        "          except KeyError:\n",
        "            nd[word] = 1\n",
        "       self.corpus_size += 1\n",
        "    \n",
        "    self.avgdl = num_doc / self.corpus_size\n",
        "    return nd\n",
        "\n",
        "  def _calc_k(self, nd):\n",
        "    idf_sum = 0\n",
        "    negative_idfs = []\n",
        "\n",
        "    for word, freq in nd.items():\n",
        "      idf = math.log(self.corpus_size - freq + 0.5) - math.log(freq + 0.5)\n",
        "      self.idf[word] = idf\n",
        "      idf_sum += idf\n",
        "      if idf < 0:\n",
        "        negative_idfs.append(word)\n",
        "    self.average_idf = idf_sum / len(self.idf)\n",
        "    eps = self.epsilon * self.average_idf\n",
        "    for word in negative_idfs:\n",
        "      self.idf[word] = eps\n",
        "\n",
        "  def get_top_n(self, query, documents, n=5):\n",
        "    assert self.corpus_size == len(documents), \"The documents given don't match the index corpus!\"\n",
        "    scores = self.get_scores(query)\n",
        "    top_n = np.argsort(scores)[::-1][:n]\n",
        "    return [documents[i] for i in top_n]\n",
        "\n",
        "  def get_scores(self, query):\n",
        "    score = np.zeros(self.corpus_size)\n",
        "    doc_len = np.array(self.doc_len)\n",
        "\n",
        "    for q in query:\n",
        "       q_freq = np.array([(doc.get(q) or 0) for doc in self.doc_freqs])\n",
        "       score += (self.idf.get(q) or 0) * (q_freq * (self.k1 + 1) /(q_freq + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl)))\n",
        "    \n",
        "    return score"
      ],
      "metadata": {
        "id": "kpcWq91OkfBM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "import spacy\n",
        "# from rank_bm25 import BM25Okapi\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import import_ipynb\n",
        "\n",
        "\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n"
      ],
      "metadata": {
        "id": "6BfxdQtt57dd"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('titles.csv')"
      ],
      "metadata": {
        "id": "0DLkTG3q6Gor"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['description']= df['description'].astype(str)\n",
        "\n",
        "df['search_text']=df['release_year'].astype(str)+' '+df['type'].astype(str)+' '+ df['title'].astype(str)+' '+df['description']"
      ],
      "metadata": {
        "id": "tOR4LH1SEFJz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text_list = df.search_text.str.lower().values\n",
        "tok_text=[] # for our tokenised corpus\n",
        "#Tokenising using SpaCy:\n",
        "for doc in tqdm(nlp.pipe(text_list, disable=[\"tagger\", \"parser\",\"ner\"])):\n",
        "   tok = [t.text for t in doc if t.is_alpha]\n",
        "   tok_text.append(tok)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxTXLC2Y5_pa",
        "outputId": "ae980ed6-9ad6-48b5-ac6b-0271eed670f5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]/usr/local/lib/python3.9/dist-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n",
            "5850it [00:18, 310.13it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bm25 = BM25Okapi(tok_text)"
      ],
      "metadata": {
        "id": "fleI9bqjhAPM"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flag=True\n",
        "while (flag==True):\n",
        "  query = input(\"Enter text : \")\n",
        "  tokenized_query = query.lower().split(\" \")\n",
        "\n",
        "  t0 = time.time()\n",
        "  results = bm25.get_top_n(tokenized_query, df.search_text.values, n=5)\n",
        "  t1 = time.time()\n",
        "  print(f'Searched 5851 records in {round(t1-t0,3) } seconds \\n')\n",
        "\n",
        "  for i in results:\n",
        "    print(i+\"\\n\")\n",
        "  \n",
        "  print(\"Want to search more , Press 1 else press any number to end your search\")\n",
        "  n=int(input())\n",
        "  if(n!=1):\n",
        "    flag=False\n",
        "    \n",
        "\n",
        "print(\"Search Complete !!\")"
      ],
      "metadata": {
        "id": "jxeKIrZGhHH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6f77f36-12d5-4607-8433-2497941f34d4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter text : horror comedy\n",
            "Searched 5851 records in 0.011 seconds \n",
            "\n",
            "2019 MOVIE Uncle Naji in UAE Naji decides with his friends to go on holiday to a mountainous region, they face many funny and strange comedy situations ,but unexpected moment happened turned their funny journey to horror, fear and mystery.\n",
            "\n",
            "2020 MOVIE Ghost Stories An anthology of four short horror tales.\n",
            "\n",
            "1995 SHOW Goosebumps Anything can turn spooky in this horror anthology series based on the best-selling books by master of kid horror, R.L. Stine. In every episode, see what happens when regular kids find themselves in scary situations, and how they work to confront and overcome their fears.\n",
            "\n",
            "2020 SHOW A Perfect Day for Arsenide A Perfect Day for Arsenide adapts ten stories from the same-titled novel by Hong Kong writer Pizza, the author of Lost On A Red Mini Bus To Taipo. Spanning suspense, horror, comedy, fantasy and more, the inventive series rolls out whimsical and bizarre stories about the absurdity of life in the wild city of Hong Kong.\n",
            "\n",
            "2020 SHOW Bloodride The doomed passengers aboard a spectral bus head toward a gruesome, unknown destination in this deliciously macabre horror anthology series.\n",
            "\n",
            "Want to search more , Press 1 else press any number to end your search\n",
            "1\n",
            "Enter text : love story\n",
            "Searched 5851 records in 0.024 seconds \n",
            "\n",
            "2020 MOVIE Soulmate A romantic film presenting a love story that is both sweet and bitter. Can love be found amidst clashes and troubles?\n",
            "\n",
            "2016 MOVIE Crouching Tiger, Hidden Dragon: Sword of Destiny A story of lost love, young love, a legendary sword and one last opportunity at redemption.\n",
            "\n",
            "2020 MOVIE Love Aaj Kal When professional ambitions clash with personal feelings for a modern-day couple, a love story from a bygone era may offer some wisdom.\n",
            "\n",
            "2020 MOVIE Love The story of a family and the various situations navigated by a husband and wife.\n",
            "\n",
            "2021 MOVIE Fine Wine A beautiful love story that can happen between two people regardless of their age gaps.\n",
            "\n",
            "Want to search more , Press 1 else press any number to end your search\n",
            "0\n",
            "Search Complete !!\n"
          ]
        }
      ]
    }
  ]
}